{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The operation couldnâ€™t be completed. Unable to locate a Java Runtime that supports apt.\n",
      "Please visit http://www.java.com for information on installing Java.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!apt update && apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import nullcontext\n",
    "from model import Whisper\n",
    "from utils import TokensPerSecondTimer\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import AudioDatasetFake, SpectrogramDataset, Batch, LexDataset\n",
    "import torch\n",
    "import time\n",
    "\n",
    "tokenizer = get_tokenizer(True, language='en', task='transcribe')\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "\n",
    "num_to_generate = 64\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU - loading medium model')\n",
    "    model = Whisper.load_from_pretrained(\"medium\")\n",
    "    model.to('cuda')\n",
    "    print('Compiling model')\n",
    "    unoptimized_model = model\n",
    "    model = torch.compile(unoptimized_model) # pytorch 2.0\n",
    "    print('Loading dataset')\n",
    "    dataset = SpectrogramDataset(LexDataset())\n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "    dtype = torch.float16\n",
    "    ctx = torch.amp.autocast(device_type='cuda', dtype=dtype)\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    model = Whisper.load_from_pretrained(\"tiny\")\n",
    "    dataset = SpectrogramDataset(AudioDatasetFake())\n",
    "    batch_size = 2\n",
    "    num_workers = 0\n",
    "    dtype = torch.float32\n",
    "    ctx = nullcontext()\n",
    "    device = 'cpu'\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, collate_fn=Batch.collate_fn)\n",
    "dataloader_iter = iter(dataloader)\n",
    "def get_batch():\n",
    "    try:\n",
    "        return (\n",
    "            next(dataloader_iter).to(device),\n",
    "            torch.tensor([50258, 50259, 50359, 50363], dtype=torch.int64).repeat(batch_size, 1).to(device),\n",
    "            #tokenizer.encode('<|startoftranscript|><|en|><|transcribe|><|notimestamps|>', allowed_special={'<|startoftranscript|>', '<|en|>', '<|transcribe|>', '<|notimestamps|>'})\n",
    "        )\n",
    "    except StopIteration:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "-5.773551940917969\n",
      "7.718759059906006\n",
      "25.459793090820312\n",
      "31.683210372924805\n",
      "37.67772674560547\n",
      "14.447501182556152\n",
      "7.189600944519043\n",
      "38.71146774291992\n",
      "35.253395080566406\n",
      "19.81686782836914\n",
      "6.911682605743408\n",
      "8.963393211364746\n",
      "-2.6529881954193115\n",
      "1.9277257919311523\n",
      "10.174867630004883\n",
      "-2.4632441997528076\n",
      "29.83599281311035\n",
      "12.924864768981934\n",
      "29.00969123840332\n",
      "25.301349639892578\n",
      "33.810150146484375\n",
      "29.957555770874023\n",
      "17.558969497680664\n",
      "2.7650229930877686\n",
      "23.852235794067383\n",
      "2.300333261489868\n",
      "10.68060302734375\n",
      "41.86252212524414\n",
      "26.616365432739258\n",
      "-1.5971943140029907\n",
      "21.53993797302246\n",
      "12.066537857055664\n",
      "-0.34007346630096436\n",
      "-3.0347888469696045\n",
      "-1.5243186950683594\n",
      "0.7232425212860107\n",
      "3.2335762977600098\n",
      "6.375285625457764\n",
      "8.93490982055664\n",
      "13.142239570617676\n",
      "14.69994831085205\n",
      "16.05259895324707\n",
      "17.54960823059082\n",
      "20.314781188964844\n",
      "13.974905014038086\n",
      "14.587306022644043\n",
      "13.32923698425293\n",
      "13.073711395263672\n",
      "12.79568099975586\n",
      "12.455617904663086\n",
      "12.086496353149414\n",
      "12.39461898803711\n",
      "12.210887908935547\n",
      "11.972715377807617\n",
      "11.837188720703125\n",
      "11.603785514831543\n",
      "11.872488975524902\n",
      "11.800344467163086\n",
      "11.91241455078125\n",
      "11.924607276916504\n",
      "11.788040161132812\n",
      "12.089604377746582\n",
      "11.487913131713867\n",
      "12.353760719299316\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>33333333333333333333333\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>33333333333333333333333\n",
      "Running: -1 tokens/s, 2.0254111289978027 s/batch, 29.623615245803798hours transcribed/h\n",
      "Batch 1\n",
      "-5.773551940917969\n",
      "7.718759059906006\n",
      "25.459793090820312\n",
      "31.683210372924805\n",
      "37.67772674560547\n",
      "14.447501182556152\n",
      "7.189600944519043\n",
      "38.71146774291992\n",
      "35.253395080566406\n",
      "19.81686782836914\n",
      "6.911682605743408\n",
      "8.963393211364746\n",
      "-2.6529881954193115\n",
      "1.9277257919311523\n",
      "10.174867630004883\n",
      "-2.4632441997528076\n",
      "29.83599281311035\n",
      "12.924864768981934\n",
      "29.00969123840332\n",
      "25.301349639892578\n",
      "33.810150146484375\n",
      "29.957555770874023\n",
      "17.558969497680664\n",
      "2.7650229930877686\n",
      "23.852235794067383\n",
      "2.300333261489868\n",
      "10.68060302734375\n",
      "41.86252212524414\n",
      "26.616365432739258\n",
      "-1.5971943140029907\n",
      "21.53993797302246\n",
      "12.066537857055664\n",
      "-0.34007346630096436\n",
      "-3.0347888469696045\n",
      "-1.5243186950683594\n",
      "0.7232425212860107\n",
      "3.2335762977600098\n",
      "6.375285625457764\n",
      "8.93490982055664\n",
      "13.142239570617676\n",
      "14.69994831085205\n",
      "16.05259895324707\n",
      "17.54960823059082\n",
      "20.314781188964844\n",
      "13.974905014038086\n",
      "14.587306022644043\n",
      "13.32923698425293\n",
      "13.073711395263672\n",
      "12.79568099975586\n",
      "12.455617904663086\n",
      "12.086496353149414\n",
      "12.39461898803711\n",
      "12.210887908935547\n",
      "11.972715377807617\n",
      "11.837188720703125\n",
      "11.603785514831543\n",
      "11.872488975524902\n",
      "11.800344467163086\n",
      "11.91241455078125\n",
      "11.924607276916504\n",
      "11.788040161132812\n",
      "12.089604377746582\n",
      "11.487913131713867\n",
      "12.353760719299316\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>33333333333333333333333\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>33333333333333333333333\n",
      "Running: -1 tokens/s, 1.9755809307098389 s/batch, 30.37081349962293hours transcribed/h\n",
      "Batch 2\n",
      "-5.773551940917969\n",
      "7.718759059906006\n",
      "25.459793090820312\n",
      "31.683210372924805\n",
      "37.67772674560547\n",
      "14.447501182556152\n",
      "7.189600944519043\n",
      "38.71146774291992\n",
      "35.253395080566406\n",
      "19.81686782836914\n",
      "6.911682605743408\n",
      "8.963393211364746\n",
      "-2.6529881954193115\n",
      "1.9277257919311523\n",
      "10.174867630004883\n",
      "-2.4632441997528076\n",
      "29.83599281311035\n",
      "12.924864768981934\n",
      "29.00969123840332\n",
      "25.301349639892578\n",
      "33.810150146484375\n",
      "29.957555770874023\n",
      "17.558969497680664\n",
      "2.7650229930877686\n",
      "23.852235794067383\n",
      "2.300333261489868\n",
      "10.68060302734375\n",
      "41.86252212524414\n",
      "26.616365432739258\n",
      "-1.5971943140029907\n",
      "21.53993797302246\n",
      "12.066537857055664\n",
      "-0.34007346630096436\n",
      "-3.0347888469696045\n",
      "-1.5243186950683594\n",
      "0.7232425212860107\n",
      "3.2335762977600098\n",
      "6.375285625457764\n",
      "8.93490982055664\n",
      "13.142239570617676\n",
      "14.69994831085205\n",
      "16.05259895324707\n",
      "17.54960823059082\n",
      "20.314781188964844\n",
      "13.974905014038086\n",
      "14.587306022644043\n",
      "13.32923698425293\n",
      "13.073711395263672\n",
      "12.79568099975586\n",
      "12.455617904663086\n",
      "12.086496353149414\n",
      "12.39461898803711\n",
      "12.210887908935547\n",
      "11.972715377807617\n",
      "11.837188720703125\n",
      "11.603785514831543\n",
      "11.872488975524902\n",
      "11.800344467163086\n",
      "11.91241455078125\n",
      "11.924607276916504\n",
      "11.788040161132812\n",
      "12.089604377746582\n",
      "11.487913131713867\n",
      "12.353760719299316\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>33333333333333333333333\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>33333333333333333333333\n",
      "Running: -1 tokens/s, 2.0837290287017822 s/batch, 28.794530945984643hours transcribed/h\n",
      "Batch 3\n",
      "-5.773551940917969\n",
      "7.718759059906006\n",
      "25.459793090820312\n",
      "31.683210372924805\n",
      "37.67772674560547\n",
      "14.447501182556152\n",
      "7.189600944519043\n",
      "38.71146774291992\n",
      "35.253395080566406\n",
      "19.81686782836914\n",
      "6.911682605743408\n",
      "8.963393211364746\n",
      "-2.6529881954193115\n",
      "1.9277257919311523\n",
      "10.174867630004883\n",
      "-2.4632441997528076\n",
      "29.83599281311035\n",
      "12.924864768981934\n",
      "29.00969123840332\n",
      "25.301349639892578\n",
      "33.810150146484375\n",
      "29.957555770874023\n",
      "17.558969497680664\n",
      "2.7650229930877686\n",
      "23.852235794067383\n",
      "2.300333261489868\n",
      "10.68060302734375\n",
      "41.86252212524414\n",
      "26.616365432739258\n",
      "-1.5971943140029907\n",
      "21.53993797302246\n",
      "12.066537857055664\n",
      "-0.34007346630096436\n",
      "-3.0347888469696045\n",
      "-1.5243186950683594\n",
      "0.7232425212860107\n",
      "3.2335762977600098\n",
      "6.375285625457764\n",
      "8.93490982055664\n",
      "13.142239570617676\n",
      "14.69994831085205\n",
      "16.05259895324707\n",
      "17.54960823059082\n",
      "20.314781188964844\n",
      "13.974905014038086\n",
      "14.587306022644043\n",
      "13.32923698425293\n",
      "13.073711395263672\n",
      "12.79568099975586\n",
      "12.455617904663086\n",
      "12.086496353149414\n",
      "12.39461898803711\n",
      "12.210887908935547\n",
      "11.972715377807617\n",
      "11.837188720703125\n",
      "11.603785514831543\n",
      "11.872488975524902\n",
      "11.800344467163086\n",
      "11.91241455078125\n",
      "11.924607276916504\n",
      "11.788040161132812\n",
      "12.089604377746582\n",
      "11.487913131713867\n",
      "12.353760719299316\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>33333333333333333333333\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>33333333333333333333333\n",
      "Running: 59.437871714409965 tokens/s, 1.9630961418151855 s/batch, 30.56396409832518hours transcribed/h\n"
     ]
    }
   ],
   "source": [
    "timer = TokensPerSecondTimer(tokens_per_call=batch_size * num_to_generate)\n",
    "hours_per_batch = batch_size * 30 / 3600\n",
    "\n",
    "batch, base_tokens = get_batch()\n",
    "i = 0\n",
    "while batch is not None:\n",
    "    print(f'Batch {i}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # GPU Work    \n",
    "    encoder_logits = model.encoder(batch.inputs)\n",
    "    output = model.generate(base_tokens, encoder_logits, max_new_tokens=num_to_generate, use_cache=False)\n",
    "\n",
    "    for x in range(output.shape[0]):\n",
    "        print(tokenizer.decode(output[x].cpu()))\n",
    "        \n",
    "    time_elapsed = time.time() - start_time \n",
    "    tokens_per_second = timer()\n",
    "    print(f'Running: {tokens_per_second} tokens/s, {time_elapsed} s/batch, {(hours_per_batch / time_elapsed) * 60* 60}hours transcribed/h')\n",
    "\n",
    "    batch, base_tokens = get_batch()\n",
    "    i += 1\n",
    "\n",
    "\n",
    "# Incorrect\n",
    "# -5.773551940917969\n",
    "# -5.742635250091553\n",
    "# -4.675758361816406\n",
    "# -3.0309195518493652\n",
    "# -3.0745980739593506\n",
    "\n",
    "\n",
    "# Correct\n",
    "# -5.773551940917969\n",
    "# 7.718759059906006\n",
    "# 25.459793090820312\n",
    "# 31.683210372924805\n",
    "# 37.67772674560547\n",
    "# 14.447501182556152\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
