{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/.pyenv/versions/3.10.6/lib/python3.10/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "from model import Whisper\n",
    "from utils import TokensPerSecondTimer\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import AudioDatasetFake, SpectrogramDataset, Batch, LexDataset\n",
    "import torch\n",
    "import time\n",
    "\n",
    "tokenizer = get_tokenizer(True, language='en', task='transcribe')\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "\n",
    "num_to_generate = 64\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU - loading medium model')\n",
    "    model = Whisper.load_from_pretrained(\"medium\")\n",
    "    model.to('cuda')\n",
    "    print('Compiling model')\n",
    "    unoptimized_model = model\n",
    "    model = torch.compile(unoptimized_model) # pytorch 2.0\n",
    "    print('Loading dataset')\n",
    "    dataset = SpectrogramDataset(LexDataset())\n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "    dtype = torch.float16\n",
    "    ctx = torch.amp.autocast(device_type='cuda', dtype=dtype)\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    model = Whisper.load_from_pretrained(\"tiny\")\n",
    "    dataset = SpectrogramDataset(AudioDatasetFake())\n",
    "    batch_size = 2\n",
    "    num_workers = 0\n",
    "    dtype = torch.float32\n",
    "    ctx = nullcontext()\n",
    "    device = 'cpu'\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, collate_fn=Batch.collate_fn)\n",
    "dataloader_iter = iter(dataloader)\n",
    "def get_batch():\n",
    "    try:\n",
    "        return (\n",
    "            next(dataloader_iter).to(device),\n",
    "            torch.tensor([tokenizer.sot_sequence], dtype=torch.int64).repeat(batch_size, 1).to(device),\n",
    "        )\n",
    "    except StopIteration:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>3333333333333333333333\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>3333333333333333333333\n",
      "Running: -1 tokens/s, 2.1980910301208496 s/batch, 0.4549402123464471hours transcribed/m\n",
      "Batch 2\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>3333333333333333333333\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>3333333333333333333333\n",
      "Running: -1 tokens/s, 2.108654022216797 s/batch, 0.47423616651380046hours transcribed/m\n",
      "Batch 2\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>3333333333333333333333\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>3333333333333333333333\n",
      "Running: -1 tokens/s, 2.2057511806488037 s/batch, 0.4533602922999947hours transcribed/m\n",
      "Batch 2\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>3333333333333333333333\n",
      "<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the exhibition.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>3333333333333333333333\n",
      "Running: 48.88847696539548 tokens/s, 2.433781862258911 s/batch, 0.41088316726621155hours transcribed/m\n"
     ]
    }
   ],
   "source": [
    "timer = TokensPerSecondTimer(tokens_per_call=batch_size * num_to_generate)\n",
    "hours_per_batch = batch_size * 30 / 3600\n",
    "\n",
    "batch, base_tokens = get_batch()\n",
    "i = 0\n",
    "while batch is not None:\n",
    "    print(f'Batch {i}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # GPU Work    \n",
    "    encoder_logits = model.encoder(batch.inputs)\n",
    "    output = model.generate(base_tokens, encoder_logits, max_new_tokens=num_to_generate)\n",
    "\n",
    "    for i in range(output.shape[0]):\n",
    "        print(tokenizer.decode(output[i].cpu()))\n",
    "        \n",
    "    time_elapsed = time.time() - start_time \n",
    "    tokens_per_second = timer()\n",
    "    print(f'Running: {tokens_per_second} tokens/s, {time_elapsed} s/batch, {(hours_per_batch / time_elapsed) * 60}hours transcribed/m')\n",
    "\n",
    "    batch, base_tokens = get_batch()\n",
    "    i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
